{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 19:21:53,259\tINFO worker.py:1625 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import ray\n",
    "\n",
    "ray.init(num_cpus=16)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_sharpe(self, weights, cov_matrix):\n",
    "    portfolio_return = np.dot(weights, mean_return.values)\n",
    "    portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    sharpe_ratio = portfolio_return  / portfolio_volatility\n",
    "    return -sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_shrinkage(corr_matrix, args):\n",
    "    return corr_matrix\n",
    "    \n",
    "def linear_shrinkage(corr_matrix, alpha:int): # cov_matrix를 corr_matrix로 변환하는 과정이 필요함!\n",
    "    '''Method of A'''\n",
    "    return  alpha * np.identity(corr_matrix.shape[0]) + (1-alpha) * corr_matrix\n",
    "    \n",
    "def constant_correlation_model(corr_matrix, args): # cov_matrix를 corr_matrix로 변환하는 과정이 필요함!\n",
    "    '''Method B'''\n",
    "    n = len(corr_matrix)\n",
    "    sum_r = np.sum(corr_matrix).sum() - np.sum(np.diag(corr_matrix)).sum()\n",
    "    r = sum_r / (n*(n-1))\n",
    "    return np.full(corr_matrix.shape, fill_value=r) - ((r-1) * np.identity(n))\n",
    "    \n",
    "def eigenvalue_clipping(corr_matrix, k:int): # cov_matrix를 corr_matrix로 변환\n",
    "    '''Method C'''\n",
    "    eigen_value, eigen_vector = np.linalg.eigh(corr_matrix)\n",
    "    eigen_value_bigger = np.where(eigen_value >= k, eigen_value, 0)\n",
    "    eigen_value_smaller = eigen_value[eigen_value_bigger == 0]\n",
    "    eigen_value_otherwise = np.nanmean(eigen_value_smaller)\n",
    "    # Result\n",
    "    eigen_value_clipped = np.where(eigen_value >= k, eigen_value_bigger, eigen_value_otherwise)\n",
    "    return eigen_vector @ np.diag(eigen_value_clipped) @ eigen_vector.T\n",
    "    \n",
    "def kmeans_clustering(self, corr_matrix, alpha:float):\n",
    "    rtn_use = self.rtn_sample.copy()\n",
    "        \n",
    "    t,n = len(rtn_use.index), len(rtn_use.columns)\n",
    "    q = n/t\n",
    "    lambda_plus = 1 + 2*(np.sqrt(q)) + q\n",
    "    # Cluster의 개수를 구하기(RMT 이론에 의해)\n",
    "    eigen_values = np.linalg.eigvalsh(corr_matrix)\n",
    "    k = (eigen_values > lambda_plus).sum() #  k가 클러스터의 수\n",
    "    self.k = k\n",
    "        \n",
    "        # NaN 값 처리를 위해\n",
    "    mean = rtn_use.mean(1)\n",
    "    data = rtn_use.dropna(thresh=1).T.fillna(mean)\n",
    "\n",
    "    kmean = KMeans(n_clusters=k, n_init=200,max_iter=1000)\n",
    "    kmean.fit(data.values)\n",
    "    label = kmean.labels_ #라벨의 순서는 cov_matrix의 (idx,col)순서와 동일하다\n",
    "        \n",
    "    within_corr_dict = {}\n",
    "    between_corr_dict = {}\n",
    "        \n",
    "        # within corr 구하기\n",
    "    for i in range(k): # i는 클러스터를 의미\n",
    "        mask = (label == i)\n",
    "        card_cluster = mask.sum()\n",
    "        cluster_corr = rtn_use.loc[:,mask].corr().values\n",
    "        with_in_cluster = (cluster_corr - np.diag(np.diag(cluster_corr))).sum() / (card_cluster * (card_cluster-1))\n",
    "        if np.isnan(with_in_cluster) == True:\n",
    "            with_in_cluster = 0\n",
    "        within_corr_dict[i] = with_in_cluster \n",
    "\n",
    "        # Between corr 구하기\n",
    "    for i in range(k): # i는 클러스터를 의미\n",
    "        mask_i = (label == i)\n",
    "        card_i = mask_i.sum()\n",
    "\n",
    "        for j in range(k): # 클러스터 j를 뽑고\n",
    "            if i == j:\n",
    "                continue\n",
    "            mask_j = (label == j)\n",
    "            card_j = mask_j.sum()\n",
    "\n",
    "            all_corr = rtn_use.loc[:, mask_i+mask_j].corr().values\n",
    "            all_corr_sum = (np.triu(all_corr) - np.diag(np.diag(all_corr))).sum()\n",
    "\n",
    "            inner_corr_i = rtn_use.loc[:, mask_i].corr().values\n",
    "            all_corr_sum_i = (np.triu(inner_corr_i) - np.diag(np.diag(inner_corr_i))).sum()        \n",
    "\n",
    "            inner_corr_j = rtn_use.loc[:, mask_j].corr().values\n",
    "            all_corr_sum_j = (np.triu(inner_corr_j) - np.diag(np.diag(inner_corr_j))).sum()   \n",
    "\n",
    "            final_corr = all_corr_sum - all_corr_sum_i - all_corr_sum_j    \n",
    "\n",
    "            between_cluster = final_corr / (2* card_i * card_j)\n",
    "            between_corr_dict[(i,j)] = between_cluster\n",
    "                \n",
    "        # Within Correlation으로 S를 (i,j) 원소에 채우기... (i,j는 하나의 클러스터에 포함됨...)\n",
    "    cor_matrix_cluster = pd.DataFrame(index=corr_matrix.index,\n",
    "                                      columns=corr_matrix.columns)\n",
    "        \n",
    "    for i in range(k): # i는 각 클러스터를 의미함\n",
    "        mask = (label == i)\n",
    "        within_corr = within_corr_dict[i] # 이 within_corr을 각 회사의 pair 자리에 채워야함\n",
    "            \n",
    "            # select the rows and columns corresponding to the True values\n",
    "        selected_rows = cor_matrix_cluster.loc[mask, :]\n",
    "        selected_cols = cor_matrix_cluster.loc[:, mask]\n",
    "            # fill in the selected values with a specific value \n",
    "        selected_rows.loc[:, selected_cols.columns] = within_corr\n",
    "        selected_cols.loc[selected_rows.index, :] = within_corr\n",
    "            # update the original correlation matrix with the modified values\n",
    "        cor_matrix_cluster.loc[mask, :] = selected_rows\n",
    "        cor_matrix_cluster.loc[:, mask] = selected_cols\n",
    "    np.fill_diagonal(cor_matrix_cluster.values, 1) # 대각 행렬에 1을 채운다\n",
    "\n",
    "        # Between corr으로 각 위치에 값을 채우기: 각 클러스터 p,q에서 pair에서 주식을 뽑고\n",
    "        ## 주식 i, j자리에 행렬을 between corr으로 채운다\n",
    "    for (p,q), between_corr in between_corr_dict.items(): # p,q는 클러스터를 의미함\n",
    "        mask_p = (label == p)\n",
    "        mask_q = (label == q)\n",
    "        for i,bol_i in enumerate(mask_p): # i,j는 각각 클러스터에서 기업의 bol값을 의미함\n",
    "            if bol_i:\n",
    "                for j, bol_j in enumerate(mask_q):\n",
    "                    if bol_j:\n",
    "                        cor_matrix_cluster.iloc[i,j] = between_corr\n",
    "        \n",
    "    reduced = alpha * cor_matrix_cluster + (1-alpha) * corr_matrix\n",
    "    return reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_mask = pd.read_pickle(\"Data/spx_mask.pickle\")\n",
    "rtn = pd.read_pickle(\"Data/allstock_reduced.pickle\").pct_change(fill_method=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimizer(start_year:str, end_year:str, rebalancing:str, args=None, shrinkage_method=\"None\"):\n",
    "\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    shrink = {\"None\": no_shrinkage,\n",
    "              \"linear\":linear_shrinkage,\n",
    "              \"constant\":constant_correlation_model,\n",
    "              \"clipping\":eigenvalue_clipping,\n",
    "              \"clustering\":kmeans_clustering}\n",
    "\n",
    "    weight_df = pd.DataFrame(columns=rtn.columns) # weight를 담을 dataframe\n",
    "\n",
    "    start_idx = pd.date_range(start_year,end_year, freq=f\"{rebalancing}S\")\n",
    "    end_idx = pd.date_range(start_year,end_year, freq=f\"{rebalancing}\")\n",
    "\n",
    "    for i in tqdm(range(len(end_idx))):\n",
    "            \n",
    "            # start~end의 주가를 보고 포폴 구성(Look Back Window는 1년이 된다)\n",
    "        start = (start_idx[i] - pd.Timedelta(days=365)).strftime(\"%Y-%m\") \n",
    "        end = (start_idx[i] - pd.Timedelta(days=1))             \n",
    "            \n",
    "        mask_sample = spx_mask.loc[:end].iloc[-1]\n",
    "        universe = mask_sample.loc[~mask_sample.isna()].index # S&P500 구성종목을 가져옵니다\n",
    "        rtn_lookback = rtn.loc[start:end, universe] \n",
    "           \n",
    "        rtn_vol = np.diag(rtn_lookback.std())\n",
    "        corr_matrix = rtn_lookback.corr() # corr_matrix를 추정하고, optimizer에 넣기 전에 cov_matrix로 변환해야함\n",
    "            \n",
    "        mean_return = rtn_lookback.mean()\n",
    "            \n",
    "        if shrinkage_method == \"None\" or shrinkage_method == \"constant\":\n",
    "            args = {\"args\":0}\n",
    "            \n",
    "        shrinked_corr_matrix = shrink[shrinkage_method](corr_matrix = corr_matrix, **args)\n",
    "        cov_matrix = rtn_vol.dot(shrinked_corr_matrix).dot(rtn_vol) # corr matrix를 cov matrix로 변경\n",
    "            \n",
    "        bounds = tuple((0,1) for _ in range(len(rtn_lookback.columns))) # 제약조건 setting (5% 이상 못 담도록 설정)\n",
    "        initial_weights = np.ones(len(rtn_lookback.columns)) / len(rtn_lookback.columns)\n",
    "            \n",
    "            # 최적화 수행\n",
    "        result = minimize(obj_sharpe, \n",
    "                          initial_weights, \n",
    "                          args=(cov_matrix,),\n",
    "                          method='SLSQP', \n",
    "                          constraints=constraints, \n",
    "                          bounds=bounds\n",
    "                          )\n",
    "        min_variance_weights = result.x\n",
    "        weight_df.loc[start_idx[i], universe] = min_variance_weights\n",
    "        \n",
    "    print(\"Jobs Done...\")\n",
    "    print(\"You can check .rebalancing_date\")\n",
    "    return weight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioOptimzer:\n",
    "    def __init__(self, price, spx_mask):\n",
    "        '''\n",
    "        Initialize the data (price: Price DataFrame \n",
    "                             spx_mask : S&P500 mask DataFrame)\n",
    "        '''\n",
    "        self.spx_mask = spx_mask\n",
    "        self.rtn = price.pct_change(fill_method=None)\n",
    "\n",
    "    def __obj_sharpe(self, weights, cov_matrix):\n",
    "        portfolio_return = np.dot(weights, self.mean_return.values)\n",
    "        portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "        sharpe_ratio = portfolio_return  / portfolio_volatility\n",
    "        return -sharpe_ratio\n",
    "\n",
    "    def __obj_variance(self, weight, cov_matrix):\n",
    "        '''목적 함수 정의(최소 분산)'''\n",
    "        return np.dot(weight.T, np.dot(cov_matrix, weight))\n",
    "    \n",
    "    def __no_shrinkage(self, corr_matrix, args):\n",
    "        return corr_matrix\n",
    "    \n",
    "    def __linear_shrinkage(self, corr_matrix, alpha:int): # cov_matrix를 corr_matrix로 변환하는 과정이 필요함!\n",
    "        '''Method of A'''\n",
    "        return  alpha * np.identity(corr_matrix.shape[0]) + (1-alpha) * corr_matrix\n",
    "    \n",
    "    def __constant_correlation_model(self, corr_matrix, args): # cov_matrix를 corr_matrix로 변환하는 과정이 필요함!\n",
    "        '''Method B'''\n",
    "        n = len(corr_matrix)\n",
    "        sum_r = np.sum(corr_matrix).sum() - np.sum(np.diag(corr_matrix)).sum()\n",
    "        r = sum_r / (n*(n-1))\n",
    "        return np.full(corr_matrix.shape, fill_value=r) - ((r-1) * np.identity(n))\n",
    "    \n",
    "    def __eigenvalue_clipping(self, corr_matrix, k:int): # cov_matrix를 corr_matrix로 변환\n",
    "        '''Method C'''\n",
    "        eigen_value, eigen_vector = np.linalg.eigh(corr_matrix)\n",
    "        eigen_value_bigger = np.where(eigen_value >= k, eigen_value, 0)\n",
    "        eigen_value_smaller = eigen_value[eigen_value_bigger == 0]\n",
    "        eigen_value_otherwise = np.nanmean(eigen_value_smaller)\n",
    "        # Result\n",
    "        eigen_value_clipped = np.where(eigen_value >= k, eigen_value_bigger, eigen_value_otherwise)\n",
    "        return eigen_vector @ np.diag(eigen_value_clipped) @ eigen_vector.T\n",
    "    \n",
    "    def __kmeans_clustering(self, corr_matrix, alpha:float):\n",
    "        rtn_use = self.rtn_sample.copy()\n",
    "        \n",
    "        t,n = len(rtn_use.index), len(rtn_use.columns)\n",
    "        q = n/t\n",
    "        lambda_plus = 1 + 2*(np.sqrt(q)) + q\n",
    "        # Cluster의 개수를 구하기(RMT 이론에 의해)\n",
    "        eigen_values = np.linalg.eigvalsh(corr_matrix)\n",
    "        k = (eigen_values > lambda_plus).sum() #  k가 클러스터의 수\n",
    "        self.k = k\n",
    "        \n",
    "        # NaN 값 처리를 위해\n",
    "        mean = rtn_use.mean(1)\n",
    "        data = rtn_use.dropna(thresh=1).T.fillna(mean)\n",
    "\n",
    "        kmean = KMeans(n_clusters=k, n_init=200,max_iter=1000)\n",
    "        kmean.fit(data.values)\n",
    "        label = kmean.labels_ #라벨의 순서는 cov_matrix의 (idx,col)순서와 동일하다\n",
    "        \n",
    "        within_corr_dict = {}\n",
    "        between_corr_dict = {}\n",
    "        \n",
    "        # within corr 구하기\n",
    "        for i in range(k): # i는 클러스터를 의미\n",
    "            mask = (label == i)\n",
    "            card_cluster = mask.sum()\n",
    "            cluster_corr = rtn_use.loc[:,mask].corr().values\n",
    "\n",
    "            with_in_cluster = (cluster_corr - np.diag(np.diag(cluster_corr))).sum() / (card_cluster * (card_cluster-1))\n",
    "            if np.isnan(with_in_cluster) == True:\n",
    "                with_in_cluster = 0\n",
    "            within_corr_dict[i] = with_in_cluster \n",
    "\n",
    "        # Between corr 구하기\n",
    "        for i in range(k): # i는 클러스터를 의미\n",
    "            mask_i = (label == i)\n",
    "            card_i = mask_i.sum()\n",
    "\n",
    "            for j in range(k): # 클러스터 j를 뽑고\n",
    "                if i == j:\n",
    "                    continue\n",
    "                mask_j = (label == j)\n",
    "                card_j = mask_j.sum()\n",
    "\n",
    "                all_corr = rtn_use.loc[:, mask_i+mask_j].corr().values\n",
    "                all_corr_sum = (np.triu(all_corr) - np.diag(np.diag(all_corr))).sum()\n",
    "\n",
    "                inner_corr_i = rtn_use.loc[:, mask_i].corr().values\n",
    "                all_corr_sum_i = (np.triu(inner_corr_i) - np.diag(np.diag(inner_corr_i))).sum()        \n",
    "\n",
    "                inner_corr_j = rtn_use.loc[:, mask_j].corr().values\n",
    "                all_corr_sum_j = (np.triu(inner_corr_j) - np.diag(np.diag(inner_corr_j))).sum()   \n",
    "\n",
    "                final_corr = all_corr_sum - all_corr_sum_i - all_corr_sum_j    \n",
    "\n",
    "                between_cluster = final_corr / (2* card_i * card_j)\n",
    "                between_corr_dict[(i,j)] = between_cluster\n",
    "                \n",
    "        # Within Correlation으로 S를 (i,j) 원소에 채우기... (i,j는 하나의 클러스터에 포함됨...)\n",
    "        cor_matrix_cluster = pd.DataFrame(index=corr_matrix.index,\n",
    "                                          columns=corr_matrix.columns)\n",
    "        \n",
    "        for i in range(k): # i는 각 클러스터를 의미함\n",
    "            mask = (label == i)\n",
    "            within_corr = within_corr_dict[i] # 이 within_corr을 각 회사의 pair 자리에 채워야함\n",
    "            \n",
    "            # select the rows and columns corresponding to the True values\n",
    "            selected_rows = cor_matrix_cluster.loc[mask, :]\n",
    "            selected_cols = cor_matrix_cluster.loc[:, mask]\n",
    "            # fill in the selected values with a specific value \n",
    "            selected_rows.loc[:, selected_cols.columns] = within_corr\n",
    "            selected_cols.loc[selected_rows.index, :] = within_corr\n",
    "            # update the original correlation matrix with the modified values\n",
    "            cor_matrix_cluster.loc[mask, :] = selected_rows\n",
    "            cor_matrix_cluster.loc[:, mask] = selected_cols\n",
    "        np.fill_diagonal(cor_matrix_cluster.values, 1) # 대각 행렬에 1을 채운다\n",
    "\n",
    "        # Between corr으로 각 위치에 값을 채우기: 각 클러스터 p,q에서 pair에서 주식을 뽑고\n",
    "        ## 주식 i, j자리에 행렬을 between corr으로 채운다\n",
    "        for (p,q), between_corr in between_corr_dict.items(): # p,q는 클러스터를 의미함\n",
    "            mask_p = (label == p)\n",
    "            mask_q = (label == q)\n",
    "            for i,bol_i in enumerate(mask_p): # i,j는 각각 클러스터에서 기업의 bol값을 의미함\n",
    "                if bol_i:\n",
    "                    for j, bol_j in enumerate(mask_q):\n",
    "                        if bol_j:\n",
    "                            cor_matrix_cluster.iloc[i,j] = between_corr\n",
    "        \n",
    "        reduced = alpha * cor_matrix_cluster + (1-alpha) * corr_matrix\n",
    "        return reduced\n",
    "\n",
    "    def run_optimizer(self, start_year:str, end_year:str, rebalancing:str, args=None, shrinkage_method=\"None\"):\n",
    "        '''\n",
    "        포트폴리오 최적화를 수행합니다\n",
    "        start_year, end_year : 투자기간(start_year + 1년부터 실제 투자 시작)\n",
    "        rebalancing : 리벨런싱 주기 str -> [M,2M, Q, Y 등등,,,]\n",
    "        shrinkage_method : str -> [None, linear, constant, clipping, clustering]\n",
    "        \n",
    "        args : dict -> {\"alpha\":int} / {\"k\": int}\n",
    "        args 설명 -> linear: alpha=int  / clipping: k=int /clustering: alpha=float\n",
    "        \n",
    "        Return -> weight_df\n",
    "        '''\n",
    "        constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "        shrink = {\"None\": self.__no_shrinkage,\n",
    "                  \"linear\":self.__linear_shrinkage,\n",
    "                  \"constant\":self.__constant_correlation_model,\n",
    "                  \"clipping\":self.__eigenvalue_clipping,\n",
    "                  \"clustering\":self.__kmeans_clustering}\n",
    "\n",
    "        weight_df = pd.DataFrame(columns=self.rtn.columns) # weight를 담을 dataframe\n",
    "        self.k_dict = {} #kmeans일경우 k를 담는다\n",
    "\n",
    "        start_idx = pd.date_range(start_year,end_year, freq=f\"{rebalancing}S\")\n",
    "        end_idx = pd.date_range(start_year,end_year, freq=f\"{rebalancing}\")\n",
    "\n",
    "        for i in tqdm(range(len(end_idx))):\n",
    "            \n",
    "            # start~end의 주가를 보고 포폴 구성(Look Back Window는 1년이 된다)\n",
    "            start = (start_idx[i] - pd.Timedelta(days=365)).strftime(\"%Y-%m\") \n",
    "            end = (start_idx[i] - pd.Timedelta(days=1))             \n",
    "            \n",
    "            mask_sample = self.spx_mask.loc[:end].iloc[-1]\n",
    "            universe = mask_sample.loc[~mask_sample.isna()].index # S&P500 구성종목을 가져옵니다\n",
    "            rtn_lookback = self.rtn.loc[start:end, universe] \n",
    "           \n",
    "            rtn_vol = np.diag(rtn_lookback.std())\n",
    "            corr_matrix = rtn_lookback.corr() # corr_matrix를 추정하고, optimizer에 넣기 전에 cov_matrix로 변환해야함\n",
    "            \n",
    "            self.rtn_sample = rtn_lookback\n",
    "            self.mean_return = rtn_lookback.mean()\n",
    "            \n",
    "            if shrinkage_method == \"None\" or shrinkage_method == \"constant\":\n",
    "                args = {\"args\":0}\n",
    "            \n",
    "            shrinked_corr_matrix = shrink[shrinkage_method](corr_matrix = corr_matrix, **args)\n",
    "            cov_matrix = rtn_vol.dot(shrinked_corr_matrix).dot(rtn_vol) # corr matrix를 cov matrix로 변경\n",
    "            \n",
    "            if shrinkage_method == \"clustering\":\n",
    "                self.k_dict[start_idx[i]] = self.k\n",
    "                        \n",
    "            bounds = tuple((0,1) for _ in range(len(rtn_lookback.columns))) # 제약조건 setting (5% 이상 못 담도록 설정)\n",
    "            initial_weights = np.ones(len(rtn_lookback.columns)) / len(rtn_lookback.columns)\n",
    "            \n",
    "            # 최적화 수행\n",
    "            result = minimize(self.__obj_sharpe, \n",
    "                              initial_weights, \n",
    "                              args=(cov_matrix,),\n",
    "                              method='SLSQP', \n",
    "                              constraints=constraints, \n",
    "                              bounds=bounds\n",
    "                              )\n",
    "            min_variance_weights = result.x\n",
    "            weight_df.loc[start_idx[i], universe] = min_variance_weights\n",
    "        \n",
    "        print(\"Jobs Done...\")\n",
    "        print(\"You can check .rebalancing_date\")\n",
    "        return weight_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
